{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download tracts' street networks\n",
    "\n",
    "Using census tigerline shapefile of 2017 US census tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.1\n",
      "2.1\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import logging as lg\n",
    "import networkx as nx\n",
    "import os\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "ox.config(use_cache=True,\n",
    "          log_file=True,\n",
    "          log_console=True,\n",
    "          log_filename='download-tracts',\n",
    "          cache_folder=config.tracts_cache_folder)\n",
    "\n",
    "print(ox.__version__)\n",
    "print(nx.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_type = 'drive'\n",
    "retain_all = True\n",
    "simplify = True\n",
    "\n",
    "input_folder = 'input_data/tracts' #tiger tract shapefiles\n",
    "output_folder_shapefile = config.tracts_shapefile_folder #where to save graph shapefiles\n",
    "output_folder_graphml = config.tracts_graphml_folder #where to save graphml files\n",
    "output_folder_lists = config.tracts_lists_folder #where to save node/edge lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input_data/states_by_fips.json') as f:\n",
    "    fips_to_state = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_state_shapefile(state_shapefile, input_folder=input_folder):\n",
    "    \n",
    "    tracts = gpd.read_file('{}/{}'.format(input_folder, state_shapefile))\n",
    "    \n",
    "    # create the output path to save to\n",
    "    state_fips = tracts['STATEFP'].unique()[0]\n",
    "    state_folder = '{}_{}'.format(state_fips, fips_to_state[state_fips]['abbreviation'])\n",
    "    \n",
    "    ## drop the aleutian islands tract because it crosses the 180th meridian\n",
    "    tracts = tracts[tracts['GEOID'] != '02016000100']\n",
    "\n",
    "    # tigerline data is epsg:4269, but osm uses epsg:4326, so project it\n",
    "    tracts = tracts.to_crs({'init':'epsg:4326'})\n",
    "    tracts = tracts.sort_values(by='GEOID', ascending=True)\n",
    "    \n",
    "    print('{} loaded {} tracts'.format(state_folder, len(tracts)))\n",
    "    return tracts, state_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_queries(tracts):\n",
    "    \n",
    "    tracts['tract_folder'] = tracts['GEOID']\n",
    "    queries = tracts.apply(lambda row: {'tract_folder':row['tract_folder'].replace('/', '_'),\n",
    "                                        'polygon':row['geometry']}, axis=1).tolist()\n",
    "    \n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_save_graph(query, state_folder):\n",
    "    \n",
    "    output_path_shapefile = '{}/{}'.format(output_folder_shapefile, state_folder)\n",
    "    output_path_graphml = '{}/{}'.format(output_folder_graphml, state_folder)\n",
    "    output_path_lists = '{}/{}/{}'.format(output_folder_lists, state_folder, query['tract_folder'])\n",
    "\n",
    "    # load graph and save it if it hasn't already been saved in the output_path\n",
    "    if not os.path.exists('{}/{}.graphml'.format(output_path_graphml, query['tract_folder'])):\n",
    "        \n",
    "        polygon = query['polygon']\n",
    "        tract_folder = query['tract_folder']\n",
    "        graph_name = '{}_{}'.format(state_folder, tract_folder)\n",
    "        \n",
    "        # fix trivially invalid geometries (nested shells, ring self-intersections, etc)\n",
    "        polygon = polygon.buffer(0)\n",
    "\n",
    "        G = ox.graph_from_polygon(polygon=polygon,\n",
    "                                  network_type=network_type, \n",
    "                                  name=graph_name,\n",
    "                                  simplify=simplify,\n",
    "                                  retain_all=retain_all)\n",
    "\n",
    "        save_node_edge_lists(G, output_path_lists)\n",
    "        ox.save_graphml(G, folder=output_path_graphml, filename='{}.graphml'.format(tract_folder))\n",
    "        ox.save_graph_shapefile(G, folder=output_path_shapefile, filename=tract_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_node_edge_lists(G, lists_folder):\n",
    "    \n",
    "    # save node and edge lists as csv\n",
    "    nodes, edges = ox.graph_to_gdfs(G, node_geometry=False, fill_edge_geometry=False)\n",
    "    edges['length'] = edges['length'].round(3)\n",
    "\n",
    "    ecols = ['u', 'v', 'key', 'oneway', 'highway', 'name', 'length',\n",
    "             'lanes', 'width', 'est_width', 'maxspeed', 'access', 'service',\n",
    "             'bridge', 'tunnel', 'area', 'junction', 'osmid', 'ref']\n",
    "\n",
    "    edges = edges.drop(columns=['geometry']).reindex(columns=ecols)\n",
    "    nodes = nodes.reindex(columns=['osmid', 'x', 'y', 'ref', 'highway'])\n",
    "\n",
    "    if not os.path.exists(lists_folder):\n",
    "        os.makedirs(lists_folder)\n",
    "    nodes.to_csv('{}/node_list.csv'.format(lists_folder), index=False, encoding='utf-8')\n",
    "    edges.to_csv('{}/edge_list.csv'.format(lists_folder), index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74133"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many tracts are there?\n",
    "gdf = gpd.GeoDataFrame()\n",
    "for tract in os.listdir(input_folder):\n",
    "    gdf_tmp = gpd.read_file('{}/{}'.format(input_folder, tract))\n",
    "    gdf = gdf.append(gdf_tmp)\n",
    "mask = (gdf['STATEFP'] == '15') | (~gdf['NAMELSAD'].str.contains('CDP'))\n",
    "tracts = gdf[mask]\n",
    "len(tracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_AL loaded 1181 tracts\n",
      "Finished making 1179 01_AL graphs in 1.8 seconds\n",
      "\n",
      "02_AK loaded 166 tracts\n",
      "Finished making 166 02_AK graphs in 0.4 seconds\n",
      "\n",
      "04_AZ loaded 1526 tracts\n",
      "Finished making 1526 04_AZ graphs in 0.8 seconds\n",
      "\n",
      "05_AR loaded 686 tracts\n",
      "Finished making 686 05_AR graphs in 0.8 seconds\n",
      "\n",
      "06_CA loaded 8057 tracts\n",
      "Finished making 8026 06_CA graphs in 46.1 seconds\n",
      "\n",
      "08_CO loaded 1249 tracts\n",
      "Finished making 1246 08_CO graphs in 1.2 seconds\n",
      "\n",
      "09_CT loaded 833 tracts\n",
      "Finished making 827 09_CT graphs in 1.9 seconds\n",
      "\n",
      "10_DE loaded 218 tracts\n",
      "Finished making 215 10_DE graphs in 1.7 seconds\n",
      "\n",
      "11_DC loaded 179 tracts\n",
      "Finished making 179 11_DC graphs in 0.1 seconds\n",
      "\n",
      "12_FL loaded 4245 tracts\n",
      "Finished making 4187 12_FL graphs in 17.1 seconds\n",
      "\n",
      "13_GA loaded 1969 tracts\n",
      "Finished making 1963 13_GA graphs in 1.8 seconds\n",
      "\n",
      "15_HI loaded 351 tracts\n",
      "Finished making 322 15_HI graphs in 67.9 seconds\n",
      "\n",
      "16_ID loaded 298 tracts\n",
      "Finished making 298 16_ID graphs in 0.6 seconds\n",
      "\n",
      "17_IL loaded 3123 tracts\n",
      "Finished making 3118 17_IL graphs in 2.6 seconds\n",
      "\n",
      "18_IN loaded 1511 tracts\n",
      "Finished making 1508 18_IN graphs in 0.7 seconds\n",
      "\n",
      "19_IA loaded 825 tracts\n",
      "Finished making 824 19_IA graphs in 0.5 seconds\n",
      "\n",
      "20_KS loaded 770 tracts\n",
      "Finished making 770 20_KS graphs in 0.3 seconds\n",
      "\n",
      "21_KY loaded 1115 tracts\n",
      "Finished making 1115 21_KY graphs in 1.0 seconds\n",
      "\n",
      "22_LA loaded 1148 tracts\n",
      "Finished making 1137 22_LA graphs in 3.2 seconds\n",
      "\n",
      "23_ME loaded 358 tracts\n",
      "Finished making 351 23_ME graphs in 4.3 seconds\n",
      "\n",
      "24_MD loaded 1406 tracts\n",
      "Finished making 1395 24_MD graphs in 6.3 seconds\n",
      "\n",
      "25_MA loaded 1478 tracts\n",
      "Finished making 1470 25_MA graphs in 53.9 seconds\n",
      "\n",
      "26_MI loaded 2813 tracts\n",
      "Finished making 2762 26_MI graphs in 30.1 seconds\n",
      "\n",
      "27_MN loaded 1338 tracts\n",
      "Finished making 1335 27_MN graphs in 4.0 seconds\n",
      "\n",
      "28_MS loaded 664 tracts\n",
      "Finished making 661 28_MS graphs in 1.1 seconds\n",
      "\n",
      "29_MO loaded 1393 tracts\n",
      "Finished making 1392 29_MO graphs in 1.2 seconds\n",
      "\n",
      "30_MT loaded 271 tracts\n",
      "Finished making 271 30_MT graphs in 0.7 seconds\n",
      "\n",
      "31_NE loaded 532 tracts\n",
      "Finished making 532 31_NE graphs in 0.3 seconds\n",
      "\n",
      "32_NV loaded 687 tracts\n",
      "Finished making 682 32_NV graphs in 1.9 seconds\n",
      "\n",
      "33_NH loaded 295 tracts\n",
      "Finished making 294 33_NH graphs in 0.5 seconds\n",
      "\n",
      "34_NJ loaded 2010 tracts\n",
      "Finished making 2000 34_NJ graphs in 3.8 seconds\n",
      "\n",
      "35_NM loaded 499 tracts\n",
      "Finished making 498 35_NM graphs in 0.5 seconds\n",
      "\n",
      "36_NY loaded 4918 tracts\n",
      "Finished making 4888 36_NY graphs in 42.5 seconds\n",
      "\n",
      "37_NC loaded 2195 tracts\n",
      "Finished making 2180 37_NC graphs in 11.1 seconds\n",
      "\n",
      "38_ND loaded 205 tracts\n",
      "Finished making 205 38_ND graphs in 0.3 seconds\n",
      "\n",
      "39_OH loaded 2952 tracts\n",
      "Finished making 2945 39_OH graphs in 4.4 seconds\n",
      "\n",
      "40_OK loaded 1046 tracts\n",
      "Finished making 1046 40_OK graphs in 0.7 seconds\n",
      "\n",
      "41_OR loaded 834 tracts\n",
      "Finished making 826 41_OR graphs in 6.1 seconds\n",
      "\n",
      "42_PA loaded 3218 tracts\n",
      "Finished making 3216 42_PA graphs in 2.2 seconds\n",
      "\n",
      "44_RI loaded 244 tracts\n",
      "Finished making 241 44_RI graphs in 6.0 seconds\n",
      "\n",
      "45_SC loaded 1103 tracts\n",
      "Finished making 1094 45_SC graphs in 5.5 seconds\n",
      "\n",
      "46_SD loaded 222 tracts\n",
      "Finished making 222 46_SD graphs in 0.4 seconds\n",
      "\n",
      "47_TN loaded 1497 tracts\n",
      "Finished making 1497 47_TN graphs in 1.2 seconds\n",
      "\n",
      "48_TX loaded 5265 tracts\n",
      "Finished making 5249 48_TX graphs in 7.9 seconds\n",
      "\n",
      "49_UT loaded 588 tracts\n",
      "Finished making 588 49_UT graphs in 0.6 seconds\n",
      "\n",
      "50_VT loaded 184 tracts\n",
      "Finished making 184 50_VT graphs in 0.1 seconds\n",
      "\n",
      "51_VA loaded 1907 tracts\n",
      "Finished making 1892 51_VA graphs in 6.3 seconds\n",
      "\n",
      "53_WA loaded 1458 tracts\n",
      "Finished making 1446 53_WA graphs in 20.9 seconds\n",
      "\n",
      "54_WV loaded 484 tracts\n",
      "Finished making 484 54_WV graphs in 0.7 seconds\n",
      "\n",
      "55_WI loaded 1409 tracts\n",
      "Finished making 1393 55_WI graphs in 10.9 seconds\n",
      "\n",
      "56_WY loaded 132 tracts\n",
      "Finished making 132 56_WY graphs in 0.3 seconds\n",
      "\n",
      "skipping tl_2017_60_tract\n",
      "skipping tl_2017_66_tract\n",
      "skipping tl_2017_69_tract\n",
      "skipping tl_2017_72_tract\n",
      "skipping tl_2017_78_tract\n",
      "All finished in 386.8 seconds\n"
     ]
    }
   ],
   "source": [
    "all_start_time = time.time()\n",
    "\n",
    "# for each state shapefile folder in the folder of state shapefile folders\n",
    "for state_shapefile in os.listdir(input_folder):\n",
    "    \n",
    "    if state_shapefile[8:10] in fips_to_state:\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        # load shapefile to get the tract boundaries in this state\n",
    "        tracts, state_folder = load_state_shapefile(state_shapefile)\n",
    "        queries = make_queries(tracts)\n",
    "        count = 0\n",
    "\n",
    "        for query in queries:\n",
    "            try:\n",
    "                download_save_graph(query, state_folder)\n",
    "                count += 1\n",
    "            except Exception as e:\n",
    "                ox.log('\"{}\" failed: {}'.format(query['tract_folder'], e), level=lg.ERROR)\n",
    "\n",
    "\n",
    "        print('Finished making {} {} graphs in {:,.1f} seconds\\n'.format(count, state_folder, time.time()-start_time))\n",
    "        \n",
    "    else:\n",
    "        print('skipping {}'.format(state_shapefile))\n",
    "\n",
    "print('All finished in {:,.1f} seconds'.format(time.time()-all_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
