{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download cities' street networks\n",
    "\n",
    "Using census tigerline shapefile of 2017 US places (ie, cities and towns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.1\n",
      "2.1\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import logging as lg\n",
    "import networkx as nx\n",
    "import os\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "ox.config(use_cache=True,\n",
    "          log_file=True,\n",
    "          log_console=True,\n",
    "          log_filename='download-cities',\n",
    "          cache_folder=config.cities_cache_folder)\n",
    "\n",
    "print(ox.__version__)\n",
    "print(nx.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_type = 'drive'\n",
    "retain_all = True\n",
    "simplify = True\n",
    "\n",
    "input_folder = 'input_data/places' #tiger place shapefiles\n",
    "output_folder_shapefile = config.cities_shapefile_folder #where to save graph shapefiles\n",
    "output_folder_graphml = config.cities_graphml_folder #where to save graphml files\n",
    "output_folder_lists = config.cities_lists_folder #where to save node/edge lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input_data/states_by_fips.json') as f:\n",
    "    fips_to_state = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_state_shapefile(state_shapefile, input_folder=input_folder):\n",
    "    \n",
    "    gdf = gpd.read_file('{}/{}'.format(input_folder, state_shapefile))\n",
    "    \n",
    "    # create the output path to save to\n",
    "    state_fips = gdf['STATEFP'].unique()[0]\n",
    "    state_folder = '{}_{}'.format(state_fips, fips_to_state[state_fips]['abbreviation'])\n",
    "    \n",
    "    # filter geometries by non-CDP, except if this is hawaii, don't, because they're all CDPs there\n",
    "    if state_fips == '15':\n",
    "        cities = gdf\n",
    "    else:\n",
    "        cities = gdf[~gdf['NAMELSAD'].str.contains('CDP')]\n",
    "    \n",
    "    # tigerline data is epsg:4269, but osm uses epsg:4326, so project it\n",
    "    cities = cities.to_crs({'init':'epsg:4326'})\n",
    "    cities = cities.sort_values(by='GEOID', ascending=True)\n",
    "    \n",
    "    print('{} loaded {} cities'.format(state_folder, len(cities)))\n",
    "    return cities, state_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_queries(cities):\n",
    "    \n",
    "    cities['city_folder'] = cities.apply(lambda row: '{}_{}'.format(row['GEOID'],\n",
    "                                                                    row['NAME']).replace(' ', '_'), axis=1)\n",
    "    queries = cities.apply(lambda row: {'city_folder':row['city_folder'].replace('/', '_'),\n",
    "                                        'polygon':row['geometry']}, axis=1).tolist()\n",
    "    \n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_save_graph(query, state_folder):\n",
    "    \n",
    "    output_path_shapefile = '{}/{}'.format(output_folder_shapefile, state_folder)\n",
    "    output_path_graphml = '{}/{}'.format(output_folder_graphml, state_folder)\n",
    "    output_path_lists = '{}/{}/{}'.format(output_folder_lists, state_folder, query['city_folder'])\n",
    "\n",
    "    # load graph and save it if it hasn't already been saved in the output_path\n",
    "    if not os.path.exists('{}/{}.graphml'.format(output_path_graphml, query['city_folder'])):\n",
    "        \n",
    "        polygon = query['polygon']\n",
    "        city_folder = query['city_folder']\n",
    "        graph_name = '{}_{}'.format(state_folder, city_folder)\n",
    "        \n",
    "        # fix trivially invalid geometries (nested shells, ring self-intersections, etc)\n",
    "        polygon = polygon.buffer(0)\n",
    "\n",
    "        G = ox.graph_from_polygon(polygon=polygon,\n",
    "                                  network_type=network_type, \n",
    "                                  name=graph_name,\n",
    "                                  simplify=simplify,\n",
    "                                  retain_all=retain_all)\n",
    "\n",
    "        save_node_edge_lists(G, output_path_lists)\n",
    "        ox.save_graphml(G, folder=output_path_graphml, filename='{}.graphml'.format(city_folder))\n",
    "        ox.save_graph_shapefile(G, folder=output_path_shapefile, filename=city_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_node_edge_lists(G, lists_folder):\n",
    "    \n",
    "    # save node and edge lists as csv\n",
    "    nodes, edges = ox.graph_to_gdfs(G, node_geometry=False, fill_edge_geometry=False)\n",
    "    edges['length'] = edges['length'].round(3)\n",
    "\n",
    "    ecols = ['u', 'v', 'key', 'oneway', 'highway', 'name', 'length',\n",
    "             'lanes', 'width', 'est_width', 'maxspeed', 'access', 'service',\n",
    "             'bridge', 'tunnel', 'area', 'junction', 'osmid', 'ref']\n",
    "\n",
    "    edges = edges.drop(columns=['geometry']).reindex(columns=ecols)\n",
    "    nodes = nodes.reindex(columns=['osmid', 'x', 'y', 'ref', 'highway'])\n",
    "\n",
    "    if not os.path.exists(lists_folder):\n",
    "        os.makedirs(lists_folder)\n",
    "    nodes.to_csv('{}/node_list.csv'.format(lists_folder), index=False, encoding='utf-8')\n",
    "    edges.to_csv('{}/edge_list.csv'.format(lists_folder), index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19678"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many cities/towns are there?\n",
    "gdf = gpd.GeoDataFrame()\n",
    "for place in os.listdir(input_folder):\n",
    "    gdf_tmp = gpd.read_file('{}/{}'.format(input_folder, place))\n",
    "    gdf = gdf.append(gdf_tmp)\n",
    "mask = (gdf['STATEFP'] == '15') | (~gdf['NAMELSAD'].str.contains('CDP'))\n",
    "cities = gdf[mask]\n",
    "len(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_AL loaded 461 cities\n",
      "Finished making 461 01_AL graphs in 1.4 seconds\n",
      "\n",
      "02_AK loaded 148 cities\n",
      "Finished making 143 02_AK graphs in 0.7 seconds\n",
      "\n",
      "04_AZ loaded 91 cities\n",
      "Finished making 91 04_AZ graphs in 0.5 seconds\n",
      "\n",
      "05_AR loaded 501 cities\n",
      "Finished making 501 05_AR graphs in 0.8 seconds\n",
      "\n",
      "06_CA loaded 482 cities\n",
      "Finished making 482 06_CA graphs in 1.3 seconds\n",
      "\n",
      "08_CO loaded 271 cities\n",
      "Finished making 271 08_CO graphs in 0.6 seconds\n",
      "\n",
      "09_CT loaded 30 cities\n",
      "Finished making 30 09_CT graphs in 0.1 seconds\n",
      "\n",
      "10_DE loaded 57 cities\n",
      "Finished making 57 10_DE graphs in 0.1 seconds\n",
      "\n",
      "11_DC loaded 1 cities\n",
      "Finished making 1 11_DC graphs in 0.0 seconds\n",
      "\n",
      "12_FL loaded 412 cities\n",
      "Finished making 410 12_FL graphs in 1.7 seconds\n",
      "\n",
      "13_GA loaded 538 cities\n",
      "Finished making 538 13_GA graphs in 1.0 seconds\n",
      "\n",
      "15_HI loaded 151 cities\n",
      "Finished making 146 15_HI graphs in 0.8 seconds\n",
      "\n",
      "16_ID loaded 201 cities\n",
      "Finished making 201 16_ID graphs in 0.4 seconds\n",
      "\n",
      "17_IL loaded 1298 cities\n",
      "Finished making 1297 17_IL graphs in 1.8 seconds\n",
      "\n",
      "18_IN loaded 567 cities\n",
      "Finished making 567 18_IN graphs in 0.6 seconds\n",
      "\n",
      "19_IA loaded 944 cities\n",
      "Finished making 942 19_IA graphs in 1.1 seconds\n",
      "\n",
      "20_KS loaded 627 cities\n",
      "Finished making 627 20_KS graphs in 0.7 seconds\n",
      "\n",
      "21_KY loaded 420 cities\n",
      "Finished making 420 21_KY graphs in 0.8 seconds\n",
      "\n",
      "22_LA loaded 304 cities\n",
      "Finished making 304 22_LA graphs in 0.5 seconds\n",
      "\n",
      "23_ME loaded 23 cities\n",
      "Finished making 23 23_ME graphs in 0.0 seconds\n",
      "\n",
      "24_MD loaded 157 cities\n",
      "Finished making 156 24_MD graphs in 0.5 seconds\n",
      "\n",
      "25_MA loaded 53 cities\n",
      "Finished making 53 25_MA graphs in 0.1 seconds\n",
      "\n",
      "26_MI loaded 533 cities\n",
      "Finished making 533 26_MI graphs in 0.6 seconds\n",
      "\n",
      "27_MN loaded 853 cities\n",
      "Finished making 853 27_MN graphs in 0.9 seconds\n",
      "\n",
      "28_MS loaded 299 cities\n",
      "Finished making 299 28_MS graphs in 0.4 seconds\n",
      "\n",
      "29_MO loaded 955 cities\n",
      "Finished making 952 29_MO graphs in 1.6 seconds\n",
      "\n",
      "30_MT loaded 129 cities\n",
      "Finished making 129 30_MT graphs in 0.3 seconds\n",
      "\n",
      "31_NE loaded 529 cities\n",
      "Finished making 529 31_NE graphs in 0.6 seconds\n",
      "\n",
      "32_NV loaded 19 cities\n",
      "Finished making 19 32_NV graphs in 0.1 seconds\n",
      "\n",
      "33_NH loaded 13 cities\n",
      "Finished making 13 33_NH graphs in 0.0 seconds\n",
      "\n",
      "34_NJ loaded 324 cities\n",
      "Finished making 323 34_NJ graphs in 0.9 seconds\n",
      "\n",
      "35_NM loaded 105 cities\n",
      "Finished making 105 35_NM graphs in 0.2 seconds\n",
      "\n",
      "36_NY loaded 605 cities\n",
      "Finished making 602 36_NY graphs in 1.4 seconds\n",
      "\n",
      "37_NC loaded 554 cities\n",
      "Finished making 552 37_NC graphs in 2.2 seconds\n",
      "\n",
      "38_ND loaded 357 cities\n",
      "Finished making 357 38_ND graphs in 0.3 seconds\n",
      "\n",
      "39_OH loaded 931 cities\n",
      "Finished making 930 39_OH graphs in 1.0 seconds\n",
      "\n",
      "40_OK loaded 595 cities\n",
      "Finished making 589 40_OK graphs in 1.3 seconds\n",
      "\n",
      "41_OR loaded 242 cities\n",
      "Finished making 242 41_OR graphs in 0.5 seconds\n",
      "\n",
      "42_PA loaded 1013 cities\n",
      "Finished making 1012 42_PA graphs in 1.4 seconds\n",
      "\n",
      "44_RI loaded 8 cities\n",
      "Finished making 8 44_RI graphs in 0.0 seconds\n",
      "\n",
      "45_SC loaded 270 cities\n",
      "Finished making 270 45_SC graphs in 0.9 seconds\n",
      "\n",
      "46_SD loaded 312 cities\n",
      "Finished making 312 46_SD graphs in 0.3 seconds\n",
      "\n",
      "47_TN loaded 345 cities\n",
      "Finished making 345 47_TN graphs in 1.0 seconds\n",
      "\n",
      "48_TX loaded 1219 cities\n",
      "Finished making 1217 48_TX graphs in 4.1 seconds\n",
      "\n",
      "49_UT loaded 247 cities\n",
      "Finished making 247 49_UT graphs in 0.6 seconds\n",
      "\n",
      "50_VT loaded 43 cities\n",
      "Finished making 43 50_VT graphs in 0.2 seconds\n",
      "\n",
      "51_VA loaded 228 cities\n",
      "Finished making 228 51_VA graphs in 0.4 seconds\n",
      "\n",
      "53_WA loaded 281 cities\n",
      "Finished making 281 53_WA graphs in 0.4 seconds\n",
      "\n",
      "54_WV loaded 232 cities\n",
      "Finished making 232 54_WV graphs in 0.3 seconds\n",
      "\n",
      "55_WI loaded 601 cities\n",
      "Finished making 601 55_WI graphs in 1.0 seconds\n",
      "\n",
      "56_WY loaded 99 cities\n",
      "Finished making 98 56_WY graphs in 0.4 seconds\n",
      "\n",
      "All finished in 39.0 seconds\n"
     ]
    }
   ],
   "source": [
    "all_start_time = time.time()\n",
    "\n",
    "# for each state shapefile folder in the folder of state shapefile folders\n",
    "for state_shapefile in os.listdir(input_folder):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # load shapefile to get the city boundaries in this state\n",
    "    cities, state_folder = load_state_shapefile(state_shapefile)\n",
    "    queries = make_queries(cities)\n",
    "    count = 0\n",
    "    \n",
    "    for query in queries:\n",
    "        try:\n",
    "            download_save_graph(query, state_folder)\n",
    "            count += 1\n",
    "        except Exception as e:\n",
    "            ox.log('\"{}\" failed: {}'.format(query['city_folder'], e), level=lg.ERROR)\n",
    "            \n",
    "\n",
    "    print('Finished making {} {} graphs in {:,.1f} seconds\\n'.format(count, state_folder, time.time()-start_time))\n",
    "\n",
    "print('All finished in {:,.1f} seconds'.format(time.time()-all_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finished in 72,000 seconds last time"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
